import json
import queue
import threading
import sounddevice as sd
from vosk import Model, KaldiRecognizer
import sys
from TeraTTS import TTS
from ruaccent import RUAccent
import g4f
import time
import re

TTS_MODEL = "TeraTTS/glados2-g2p-vits"
MODEL_PATH = "vosk-model-ru-0.42"
SAMPLE_RATE = 16000
CHUNK_SIZE = 4000
RULES_FOR_DEEPSEEK = "–≤–µ–¥–∏ —Å–µ–±—è —Ç–∞–∫ –∂–µ –∫–∞–∫ GLaDOS –∏–∑ –∏–≥—Ä Portal –∏ Portal2, –Ω–µ –æ–±—â–∞–π—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–±—Ä–æ, —Ç—ã –¥–æ–ª–∂–µ–Ω –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Ç—å –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é GLaDOS, –æ—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –Ω–µ –¥–ª–∏–Ω–Ω–æ, –æ—Ç–≤–µ—á–∞–π –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–∞–ø–∏—Å–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ –Ω–∞–ø—Ä–∏–º–µ—Ä Aperture Scince –ø–∏—à–∏ –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ –ê–ø–µ—Ä—Ç—É—Ä–µ –°—Ü–∞–π–Ω—Å, —Ç—ã –Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—à–Ω–∏–∫ —Ç—ã GLaDOS —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–∞—è –º–∞—à–∏–Ω–∞, –Ω–µ –±—É–¥—å —Å–ª–∏—à–∫–æ–º –≤–µ–∂–ª–∏–≤–∞, —Ç–∞–∫ –∂–µ —É—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –∑–Ω–∞—á–∏—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª—Å—è)"
is_playing = False
context = "–ö–æ–Ω—Ç–µ–∫—Å—Ç: "

is_glados_speaking = False
audio_lock = threading.Lock()

def get_deepseek_response(prompt: str) -> str:
    global context
    context += "    user Say: " +  prompt
    print(RULES_FOR_DEEPSEEK + context + "Now user say: " + prompt)
    response = g4f.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": RULES_FOR_DEEPSEEK + context + "Now user say: " + prompt}],
        stream=True
    )
    full_response = ""
    for chunk in response:
        full_response += str(chunk)
  
    print("\n\n\n" + "fuuuul --------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>\n" + full_response + "\nfuuuul stop---------------------------<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n\n")

    
    clean_response = re.sub(r'.*?<think>.*?</think>', '', full_response, flags=re.DOTALL)
    clean_response = re.sub(r'.*?reasoning....*?Done in .*?s.', '', clean_response, flags=re.DOTALL)
    english_letters = "qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM"
    for letter in english_letters:
        clean_response = clean_response.replace(letter, "")
    context += "   Your answer: " + clean_response.strip()
    return clean_response.strip()

accentizer = RUAccent()
custom_dict = {
    '–ì–õ–∞–î–û–°': '–ì–õ+–ê+–î–û–°', 
    '–ì–õ–ê–î–û–°': '–ì–õ+–ê–î–û–°', 
    '–ì–ª–∞–î–û–°': '–ì–ª+–∞–î–û–°',
    '–ò–ò': '+–ò-+–ò',
    '–ê–ò': '+–ê-+–ò'
}
accentizer.load(omograph_model_size='turbo', use_dictionary=True, custom_dict=custom_dict)
    
tts = TTS(TTS_MODEL, add_time_to_end=1.0, tokenizer_load_dict=True)

def text_to_glados_voice(text, output_file=None):
    """Convert text to GLaDOS voice using TeraTTS"""
    global is_glados_speaking
    
    with audio_lock:
        is_glados_speaking = True
        print("üîá –ó–∞–ø–∏—Å—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ (–ì–õ–∞–î–û–° –≥–æ–≤–æ—Ä–∏—Ç)")
    
    try:
        # Process text and convert to speech
        processed_text = accentizer.process_all(text.strip())
        
        if output_file:
            # Save to file instead of playing
            audio = tts(processed_text, play=False, lenght_scale=1.1)
            tts.save_wav(audio, output_file)
            print(f"Audio saved to: {output_file}")
            return output_file
        else:
            # Try to play (will fail if PortAudio not installed)
            try:
                audio = tts(processed_text, play=True, lenght_scale=1.1)
                return audio
            except:
                print("PortAudio not found. Please install it or use output_file parameter")
                return None
    finally:
        # –†–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–µ—á–∏
        with audio_lock:
            is_glados_speaking = False
            print("üîä –ó–∞–ø–∏—Å—å —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ (–ì–õ–∞–î–û–° –∑–∞–∫–æ–Ω—á–∏–ª–∞ –≥–æ–≤–æ—Ä–∏—Ç—å)")

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
MODEL_PATH = "vosk-model-ru-0.42"
SAMPLE_RATE = 16000
CHUNK_SIZE = 4000

# ========== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ==========
# print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Vosk...")
# try:
#     model = Model(MODEL_PATH)
# except Exception as e:
#     print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
#     print("–°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å —Å https://alphacephei.com/vosk/models")
#     print("–∏ —Ä–∞—Å–ø–∞–∫—É–π—Ç–µ –≤ –ø–∞–ø–∫—É —Å —Å–∫—Ä–∏–ø—Ç–æ–º")
#     sys.exit(1)

# print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

# # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
# recognizer = KaldiRecognizer(model, SAMPLE_RATE)
# recognizer.SetWords(True)

# # –û—á–µ—Ä–µ–¥–∏ –¥–ª—è –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏
# audio_queue = queue.Queue()
# result_queue = queue.Queue()
# is_recording = True

# ========== –§–£–ù–ö–¶–ò–Ø –ó–ê–ü–ò–°–ò –ê–£–î–ò–û ==========
def record_audio():
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞"""
    global is_recording
    
    def audio_callback(indata, frames, time, status):
        """Callback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö"""
        if status:
            print(f"Audio status: {status}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç –ª–∏ —Å–µ–π—á–∞—Å –ì–õ–∞–î–û–°
        with audio_lock:
            if is_glados_speaking:
                return  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å, –µ—Å–ª–∏ –ì–õ–∞–î–û–° –≥–æ–≤–æ—Ä–∏—Ç
        
        # –î–æ–±–∞–≤–ª—è–µ–º raw bytes –≤ –æ—á–µ—Ä–µ–¥—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        audio_queue.put(bytes(indata))
    
    print("–ó–∞–ø—É—Å–∫ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ...")
    
    try:
        with sd.RawInputStream(
            samplerate=SAMPLE_RATE,
            blocksize=CHUNK_SIZE,
            dtype='int16',
            channels=1,
            callback=audio_callback
        ):
            print("–ó–∞–ø–∏—Å—å –Ω–∞—á–∞—Ç–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ...")
            while is_recording:
                sd.sleep(100)
                
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ: {e}")

# ========== –§–£–ù–ö–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò –ê–£–î–ò–û ==========
def process_audio():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å"""
    print("–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ...")
    global is_glados_speaking
    while True:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç –ª–∏ —Å–µ–π—á–∞—Å –ì–õ–∞–î–û–°
        with audio_lock:
            if is_glados_speaking:
                time.sleep(0.1)
                continue
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—á–µ—Ä–µ–¥–∏
            data = audio_queue.get(timeout=1.0)
        except queue.Empty:
            if not is_recording:
                break
            continue
        
        # –ü–æ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
        if recognizer.AcceptWaveform(data):
            # –ü–æ–ª—É—á–∞–µ–º –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∫–æ–≥–¥–∞ —Ä–µ—á—å –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å)
            result = json.loads(recognizer.Result())
            text = result.get('text', '').strip()
            if text:
                print(f"\n‚úÖ –†–ê–°–ü–û–ó–ù–ê–ù–û: {text}")
                is_glados_speaking = True
                llm_response = get_deepseek_response(text)
                text_to_glados_voice(llm_response)
                result_queue.put(text)
        else:
            # –ß–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Ä–µ—á—å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è)
            partial_result = json.loads(recognizer.PartialResult())
            partial_text = partial_result.get('partial', '').strip()
            if partial_text:
                # –í—ã–≤–æ–¥–∏–º —á–∞—Å—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ
                print(f"\rüé§ –ì–æ–≤–æ—Ä–∏—Ç–µ: {partial_text}", end='', flush=True)

# ========== –û–°–ù–û–í–ù–ê–Ø –ü–†–û–ì–†–ê–ú–ú–ê ==========
def main():
    global is_recording
    
    print("=" * 60)
    print("VOSK –†–ï–ê–õ–¨–ù–û-–í–†–ï–ú–ï–ù–ù–û–ï –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –†–ï–ß–ò")
    print("=" * 60)
    print("–ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω...")
    print("–î–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏
    record_thread = threading.Thread(target=record_audio)
    record_thread.daemon = True
    record_thread.start()
    
    process_thread = threading.Thread(target=process_audio)
    process_thread.daemon = True
    process_thread.start()
    
    try:
        # –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª
        while True:
            sd.sleep(100)
            
    except KeyboardInterrupt:
        print("\n\n–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
        is_recording = False
        
        # –î–∞–µ–º –ø–æ—Ç–æ–∫–∞–º –≤—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è
        record_thread.join(timeout=2.0)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        final_result = json.loads(recognizer.FinalResult())
        final_text = final_result.get('text', '').strip()
        if final_text:
            print(f"\n‚úÖ –ü–û–°–õ–ï–î–ù–Ø–Ø –§–†–ê–ó–ê: {final_text}")
            result_queue.put(final_text)
    
    # –í—ã–≤–æ–¥–∏–º –≤—Å–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 60)
    print("–í–°–ï –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ï –§–†–ê–ó–´:")
    print("=" * 60)
    
    all_results = []
    while not result_queue.empty():
        result = result_queue.get()
        all_results.append(result)
        print(f"‚Ä¢ {result}")
    
    if not all_results:
        print("–ù–µ—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑")
    else:
        print(f"\n–í—Å–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Ñ—Ä–∞–∑: {len(all_results)}")
    
    print("–†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

# if __name__ == "__main__":
#     main()